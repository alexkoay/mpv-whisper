
[model]
# Model to use
model = "base"

# Arguments passed when initializing faster-whisper
# Set `device = "cuda"` to use GPU (ensure the correct PyTorch libraries are installed)
args = { device = "cpu" }
# args = { device = "cuda", compute_type = "float16" }

# Arguments passed when executing a task 
task_args = { beam_size = 5, vad_filter = true }


[transcribe]
# Use specified language for transcription/translation, leave empty to auto-detect
# language = null

# Confidence threshold to detected language for the entire file
# Set above 1.0 to perform detection for each chunk
confidence_threshold = 0.95

# Behaviour to use when the language is not English
# "translate" / "transcribe" performs only the specified task
# "both" will transcribe and translate (timestamps may differ)
foreign_lang_behaviour = "transcribe"

# Duration of each audio chunk used in whisper. Longer chunks will take longer but provide more context
chunk_duration = 15.0


[mpv]
# Path to MPV executable if not found in PATH
# executable = null

# Starts MPV when executing the script
# Disable if attaching to a running instance of MPV using ipc_socket
start_mpv = true

# Arguments passed to MPV during startup
# Refer to https://mpv.io/manual/stable/#options for the list of configuration options
start_args = {}

# Path to IPC socket configured in MPV
# ipc_socket = null

# Keybinding to enable/disable mpv-whisper
toggle_binding = "ctrl+."


[subtitle]
# Location to store subtitle files generated by mpv-whisper
path = "~/.config/mpv-whisper/subs"

# If set to false (default), all subtitles will be stored in the path with the filename
# Otherwise, local files will be created alongside the original file
only_network = false
